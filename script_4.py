
# Create comprehensive project documentation file
project_structure_md = '''# Zomato ML Clustering - Complete Project Structure

## ğŸ“ Repository Structure

```
zomato-ml-clustering/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    # Main project documentation
â”œâ”€â”€ ğŸ“„ LICENSE                      # MIT License
â”œâ”€â”€ ğŸ“„ CONTRIBUTING.md              # Contribution guidelines
â”œâ”€â”€ ğŸ“„ .gitignore                   # Git ignore rules
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python dependencies
â”œâ”€â”€ ğŸ“„ setup.py                     # Package installation
â”œâ”€â”€ ğŸ“„ Dockerfile                   # Docker configuration
â”œâ”€â”€ ğŸ“„ .dockerignore                # Docker ignore rules
â”œâ”€â”€ ğŸ“„ .env.example                 # Environment variables template
â”‚
â”œâ”€â”€ ğŸ“‚ src/                         # Source code modules
â”‚   â”œâ”€â”€ data_processing.py          # Data cleaning and preprocessing
â”‚   â”œâ”€â”€ clustering.py               # Clustering algorithms
â”‚   â”œâ”€â”€ sentiment_analysis.py       # Sentiment analysis
â”‚   â””â”€â”€ visualization.py            # Plotting utilities (optional)
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/                   # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_EDA.ipynb               # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb      # Data preprocessing
â”‚   â”œâ”€â”€ 03_clustering.ipynb         # Clustering analysis
â”‚   â”œâ”€â”€ 04_sentiment.ipynb          # Sentiment analysis
â”‚   â””â”€â”€ 05_insights.ipynb           # Business insights
â”‚
â”œâ”€â”€ ğŸ“‚ data/                        # Data directory
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                     # Raw datasets
â”‚   â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”‚   â””â”€â”€ README.md               # Data description
â”‚   â”œâ”€â”€ ğŸ“‚ processed/               # Processed datasets
â”‚   â”‚   â””â”€â”€ .gitkeep
â”‚   â””â”€â”€ ğŸ“‚ sample/                  # Sample data for testing
â”‚       â””â”€â”€ sample_restaurants.csv
â”‚
â”œâ”€â”€ ğŸ“‚ results/                     # Analysis results
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”œâ”€â”€ ğŸ“‚ figures/                 # Generated plots
â”‚   â”œâ”€â”€ ğŸ“‚ models/                  # Saved models
â”‚   â””â”€â”€ ğŸ“‚ reports/                 # Analysis reports
â”‚
â”œâ”€â”€ ğŸ“‚ tests/                       # Unit tests (optional)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_data_processing.py
â”‚   â”œâ”€â”€ test_clustering.py
â”‚   â””â”€â”€ test_sentiment.py
â”‚
â”œâ”€â”€ ğŸ“‚ streamlit_app/               # Streamlit application (alternative structure)
â”‚   â””â”€â”€ streamlit_app.py            # Main Streamlit app
â”‚
â””â”€â”€ ğŸ“‚ docs/                        # Additional documentation
    â”œâ”€â”€ installation.md
    â”œâ”€â”€ usage_guide.md
    â”œâ”€â”€ api_reference.md
    â””â”€â”€ deployment.md
```

## ğŸš€ Quick Start Guide

### 1. Clone the Repository

```bash
git clone https://github.com/Ishadowprince716/zomato-ml-clustering.git
cd zomato-ml-clustering
```

### 2. Set Up Environment

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\\Scripts\\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Download NLTK Data (Required for Sentiment Analysis)

```python
import nltk
nltk.download('vader_lexicon')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')
```

### 4. Set Up Environment Variables

```bash
# Copy example env file
cp .env.example .env

# Edit .env and add your API keys
# GOOGLE_API_KEY=your_gemini_api_key_here
```

### 5. Run the Application

```bash
# Run Streamlit app
streamlit run streamlit_app.py

# Or run with Docker
docker build -t zomato-ml-app .
docker run -p 8501:8501 zomato-ml-app
```

## ğŸ“Š Data Preparation

### Expected Data Format

**Restaurant Data (`restaurants.csv`):**
```csv
name,location,cost,cuisines,rating,timings
Restaurant A,Delhi,800,"North Indian, Mughlai",4.5,11:00-23:00
Restaurant B,Mumbai,500,"Chinese, Thai",4.2,12:00-22:00
```

**Review Data (`reviews.csv`):**
```csv
restaurant_id,reviewer,review,rating,time,pictures
1,John Doe,Amazing food and service!,5,2024-01-15,2
2,Jane Smith,Average experience,3,2024-01-16,0
```

### Sample Data

A sample dataset is available in `data/sample/` for testing purposes.

## ğŸ”§ Module Usage

### Data Processing

```python
from src.data_processing import DataProcessor

# Initialize processor
processor = DataProcessor()

# Load data
df = processor.load_data('data/raw/restaurants.csv')

# Clean data
df = processor.handle_missing_values(df, strategy='mean')
df = processor.remove_duplicates(df)
df = processor.handle_outliers(df, columns=['cost', 'rating'])

# Encode and scale
df = processor.encode_categorical(df, columns=['cuisines'], method='label')
df = processor.scale_features(df, columns=['cost', 'rating'], method='standard')
```

### Clustering

```python
from src.clustering import RestaurantClustering

# Initialize clustering
clusterer = RestaurantClustering()

# Find optimal clusters
results = clusterer.find_optimal_clusters(X, max_clusters=10)
clusterer.plot_elbow_curve(results)

# Perform K-Means clustering
labels = clusterer.kmeans_clustering(X, n_clusters=4)

# Visualize clusters
clusterer.visualize_clusters_2d(X, df)

# Get cluster characteristics
cluster_stats = clusterer.get_cluster_characteristics(df, ['cost', 'rating'])
```

### Sentiment Analysis

```python
from src.sentiment_analysis import SentimentAnalyzer

# Initialize analyzer
analyzer = SentimentAnalyzer()

# Analyze reviews
results = analyzer.analyze_reviews_batch(reviews, method='vader')

# Get sentiment distribution
distribution, pct = analyzer.get_sentiment_distribution(results['sentiment'])

# Extract keywords
positive_keywords = analyzer.extract_keywords(positive_reviews, top_n=20)

# Plot sentiment
analyzer.plot_sentiment_distribution(results['sentiment'])
```

## ğŸ³ Docker Deployment

### Build Image

```bash
docker build -t zomato-ml-app:latest .
```

### Run Container

```bash
docker run -d -p 8501:8501 --name zomato-app zomato-ml-app:latest
```

### Docker Compose (Optional)

Create `docker-compose.yml`:

```yaml
version: '3.8'

services:
  web:
    build: .
    ports:
      - "8501:8501"
    volumes:
      - ./data:/app/data
      - ./results:/app/results
    environment:
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
```

Run with:
```bash
docker-compose up -d
```

## ğŸŒ Deployment Options

### Streamlit Cloud

1. Push code to GitHub
2. Go to [share.streamlit.io](https://share.streamlit.io)
3. Connect your repository
4. Select `streamlit_app.py` as the main file
5. Add secrets in Streamlit Cloud dashboard
6. Deploy!

### Heroku

```bash
# Install Heroku CLI
# Create Procfile
echo "web: streamlit run streamlit_app.py --server.port=$PORT" > Procfile

# Create runtime.txt
echo "python-3.9.16" > runtime.txt

# Deploy
heroku create zomato-ml-app
git push heroku main
```

### AWS EC2

1. Launch EC2 instance (Ubuntu)
2. Install Docker
3. Clone repository
4. Build and run Docker container
5. Configure security groups (port 8501)
6. Access via public IP

## ğŸ“ Development Workflow

### Adding New Features

1. Create feature branch
   ```bash
   git checkout -b feature/new-feature
   ```

2. Make changes and test

3. Commit changes
   ```bash
   git add .
   git commit -m "Add: new feature description"
   ```

4. Push and create PR
   ```bash
   git push origin feature/new-feature
   ```

### Running Tests

```bash
# Run all tests
pytest tests/

# Run with coverage
pytest --cov=src tests/

# Run specific test
pytest tests/test_clustering.py
```

## ğŸ“ Jupyter Notebooks Guide

Navigate to notebooks and run in order:

1. **01_EDA.ipynb**: Initial data exploration
2. **02_preprocessing.ipynb**: Data cleaning and feature engineering
3. **03_clustering.ipynb**: Clustering analysis
4. **04_sentiment.ipynb**: Sentiment analysis
5. **05_insights.ipynb**: Business insights generation

## ğŸ“š Additional Resources

### Documentation
- [Installation Guide](docs/installation.md)
- [Usage Guide](docs/usage_guide.md)
- [API Reference](docs/api_reference.md)
- [Deployment Guide](docs/deployment.md)

### External Resources
- [Scikit-learn Documentation](https://scikit-learn.org/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [NLTK Documentation](https://www.nltk.org/)
- [Pandas Documentation](https://pandas.pydata.org/)

## ğŸ¤ Contributing

Please read [CONTRIBUTING.md](CONTRIBUTING.md) for details on our code of conduct and the process for submitting pull requests.

## ğŸ“„ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Authors

- **Rahul Singh Kushwah** - *Initial work* - [GitHub](https://github.com/Ishadowprince716)

## ğŸ™ Acknowledgments

- Zomato for inspiration
- Microsoft Azure for ML resources
- Open-source community
- GeeksforGeeks community

---

For questions or support, please open an issue or contact the maintainer.
'''

with open('PROJECT_STRUCTURE.md', 'w', encoding='utf-8') as f:
    f.write(project_structure_md)

print("âœ… PROJECT_STRUCTURE.md created successfully!")
